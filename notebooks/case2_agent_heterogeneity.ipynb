{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Case Study 2: Agent Heterogeneity & Market Power\n",
        "\n",
        "This notebook explores how agent heterogeneity and market power concentration affect coordination, market efficiency, and strategic behavior in decentralized local energy markets.\n",
        "\n",
        "## üìã Table of Contents\n",
        "\n",
        "1. [Research Questions & Hypothesis](#research-questions--hypothesis)\n",
        "2. [Setup & Imports](#setup--imports)\n",
        "3. [Scenario Configuration](#scenario-configuration)\n",
        "4. [Market Structure Creation](#market-structure-creation)\n",
        "5. [Training & Evaluation](#training--evaluation)\n",
        "6. [Market Power Analysis](#market-power-analysis)\n",
        "7. [Results Analysis](#results-analysis)\n",
        "8. [Research Implications](#research-implications)\n",
        "\n",
        "---\n",
        "\n",
        "## üî¨ Research Questions & Hypothesis\n",
        "\n",
        "### Research Questions Addressed:\n",
        "- How does agent size heterogeneity affect market power distribution?\n",
        "- Do dominant agents adopt different strategies compared to smaller agents?\n",
        "- What is the impact of market concentration on overall system efficiency?\n",
        "- How does agent heterogeneity affect implicit coordination effectiveness?\n",
        "- Can smaller agents coordinate to compete against dominant players?\n",
        "\n",
        "### Hypothesis:\n",
        "Market concentration will lead to strategic behavior from dominant agents, potentially reducing market efficiency, while smaller agents will need to develop more sophisticated coordination strategies to remain competitive.\n",
        "\n",
        "### Market Structures Tested:\n",
        "1. **Balanced Market:** Similar-sized agents with equal market power\n",
        "2. **Monopoly Market:** One dominant agent with 60% market share\n",
        "3. **Oligopoly Market:** Three medium-large agents vs. three small agents\n",
        "4. **Cooperative Market:** Community-owned cooperative with individual agents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üõ†Ô∏è Setup & Imports\n",
        "\n",
        "Let's import all necessary libraries and set up the environment for our agent heterogeneity analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ Imports successful!\")\n",
        "print(f\"üìÅ Project root: {project_root}\")\n",
        "print(f\"üêç Python version: {sys.version}\")\n",
        "print(f\"üìä NumPy version: {np.__version__}\")\n",
        "print(f\"üìà Pandas version: {pd.__version__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import project-specific modules\n",
        "try:\n",
        "    from src.agent.battery import Battery\n",
        "    from src.agent.der import DERAgent\n",
        "    from src.grid.network import GridNetwork, GridTopology\n",
        "    from src.market.matching import MarketConfig\n",
        "    from src.market.mechanism import ClearingMechanism\n",
        "    from src.profile.der import DERProfileHandler\n",
        "    from src.profile.dso import DSOProfileHandler\n",
        "    from src.environment.train import RLTrainer, TrainingMode, RLAlgorithm\n",
        "    \n",
        "    print(\"‚úÖ Project modules imported successfully!\")\n",
        "    \n",
        "    # Display available training modes\n",
        "    print(\"\\nüìã Available Training Modes:\")\n",
        "    for mode in TrainingMode:\n",
        "        print(f\"  - {mode.name}: {mode.value}\")\n",
        "        \n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Error importing project modules: {e}\")\n",
        "    print(\"Please ensure you're running this notebook from the correct directory\")\n",
        "    print(\"and that all dependencies are installed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è Scenario Configuration\n",
        "\n",
        "Let's define the base configuration parameters for our agent heterogeneity analysis. These parameters will be kept constant across all market structures to ensure fair comparison.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Case2Scenarios:\n",
        "    \"\"\"Case 2: Agent Heterogeneity & Market Power scenarios configuration.\"\"\"\n",
        "    \n",
        "    # Base simulation parameters\n",
        "    MAX_STEPS = 24  # 24-hour simulation\n",
        "    GRID_CAPACITY = 2000.0  # kW (larger to accommodate dominant agents)\n",
        "    \n",
        "    # Market parameters\n",
        "    MIN_PRICE = 30.0  # $/MWh\n",
        "    MAX_PRICE = 300.0  # $/MWh (wider range to observe price manipulation)\n",
        "    MIN_QUANTITY = 0.1  # kWh\n",
        "    MAX_QUANTITY = 500.0  # kWh (higher to allow large trades)\n",
        "\n",
        "# Display configuration\n",
        "print(\"üìä Case 2 Configuration:\")\n",
        "print(f\"  Simulation Length: {Case2Scenarios.MAX_STEPS} hours\")\n",
        "print(f\"  Grid Capacity: {Case2Scenarios.GRID_CAPACITY} kW\")\n",
        "print(f\"  Price Range: ${Case2Scenarios.MIN_PRICE} - ${Case2Scenarios.MAX_PRICE} /MWh\")\n",
        "print(f\"  Quantity Range: {Case2Scenarios.MIN_QUANTITY} - {Case2Scenarios.MAX_QUANTITY} kWh\")\n",
        "print(f\"  Market Structures: 4 (Balanced, Monopoly, Oligopoly, Cooperative)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è Market Structure Creation\n",
        "\n",
        "Now let's create the four different market structures to analyze how agent heterogeneity affects market dynamics and coordination.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_balanced_agents() -> List[DERAgent]:\n",
        "    \"\"\"Create balanced market scenario with similar-sized agents.\"\"\"\n",
        "    agents = []\n",
        "    profile_handler = DERProfileHandler()\n",
        "    \n",
        "    print(\"üèóÔ∏è Creating balanced market agents...\")\n",
        "    \n",
        "    # 6 agents with similar capacities (balanced market)\n",
        "    for i in range(6):\n",
        "        capacity = np.random.uniform(40.0, 60.0)  # Similar capacities\n",
        "        battery_capacity = capacity * 0.5  # 50% of generation capacity\n",
        "        \n",
        "        generation, demand = profile_handler.get_energy_profiles(\n",
        "            Case2Scenarios.MAX_STEPS,\n",
        "            capacity\n",
        "        )\n",
        "        # Apply slight demand bias for balanced market\n",
        "        demand = [d * 1.2 for d in demand]\n",
        "        \n",
        "        agent = DERAgent(\n",
        "            id=f\"balanced_{i+1:03d}\",\n",
        "            capacity=capacity,\n",
        "            battery=Battery(\n",
        "                nominal_capacity=battery_capacity,\n",
        "                min_soc=0.1,\n",
        "                max_soc=0.9,\n",
        "                charge_efficiency=0.95,\n",
        "                discharge_efficiency=0.95\n",
        "            ),\n",
        "            generation_profile=generation,\n",
        "            demand_profile=demand\n",
        "        )\n",
        "        agents.append(agent)\n",
        "        print(f\"  Created agent {i+1}/6: balanced_{i+1:03d} ({capacity:.1f} kW)\")\n",
        "    \n",
        "    print(f\"‚úÖ Created {len(agents)} balanced market agents!\")\n",
        "    return agents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_monopoly_scenario() -> List[DERAgent]:\n",
        "    \"\"\"Create scenario with one dominant agent and several small agents.\"\"\"\n",
        "    agents = []\n",
        "    profile_handler = DERProfileHandler()\n",
        "    \n",
        "    print(\"üèóÔ∏è Creating monopoly market agents...\")\n",
        "    \n",
        "    # One dominant agent with 60% of total market capacity\n",
        "    dominant_capacity = 300.0\n",
        "    dominant_battery = 150.0\n",
        "    \n",
        "    generation, demand = profile_handler.get_energy_profiles(\n",
        "        Case2Scenarios.MAX_STEPS,\n",
        "        dominant_capacity\n",
        "    )\n",
        "    # Adjust for commercial profile with lower demand to create surplus\n",
        "    demand = [d * 0.7 for d in demand]\n",
        "    \n",
        "    dominant_agent = DERAgent(\n",
        "        id=\"dominant_001\",\n",
        "        capacity=dominant_capacity,\n",
        "        battery=Battery(\n",
        "            nominal_capacity=dominant_battery,\n",
        "            min_soc=0.2,\n",
        "            max_soc=0.8,\n",
        "            charge_efficiency=0.98,  # Higher efficiency\n",
        "            discharge_efficiency=0.98\n",
        "        ),\n",
        "        generation_profile=generation,\n",
        "        demand_profile=demand\n",
        "    )\n",
        "    agents.append(dominant_agent)\n",
        "    print(f\"  Created dominant agent: dominant_001 ({dominant_capacity:.1f} kW)\")\n",
        "    \n",
        "    # Five small agents sharing remaining 40% of market\n",
        "    small_capacity_base = 25.0\n",
        "    for i in range(5):\n",
        "        capacity = small_capacity_base + np.random.uniform(-5.0, 10.0)\n",
        "        battery_capacity = capacity * 0.6\n",
        "        \n",
        "        generation, demand = profile_handler.get_energy_profiles(\n",
        "            Case2Scenarios.MAX_STEPS,\n",
        "            capacity\n",
        "        )\n",
        "        # Higher demand for small agents\n",
        "        demand = [d * 1.5 for d in demand]\n",
        "        \n",
        "        agent = DERAgent(\n",
        "            id=f\"small_{i+1:03d}\",\n",
        "            capacity=capacity,\n",
        "            battery=Battery(\n",
        "                nominal_capacity=battery_capacity,\n",
        "                min_soc=0.1,\n",
        "                max_soc=0.9,\n",
        "                charge_efficiency=0.90,  # Lower efficiency\n",
        "                discharge_efficiency=0.90\n",
        "            ),\n",
        "            generation_profile=generation,\n",
        "            demand_profile=demand\n",
        "        )\n",
        "        agents.append(agent)\n",
        "        print(f\"  Created small agent {i+1}/5: small_{i+1:03d} ({capacity:.1f} kW)\")\n",
        "    \n",
        "    print(f\"‚úÖ Created {len(agents)} monopoly market agents!\")\n",
        "    return agents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_oligopoly_scenario() -> List[DERAgent]:\n",
        "    \"\"\"Create scenario with three medium-large agents and three small agents.\"\"\"\n",
        "    agents = []\n",
        "    profile_handler = DERProfileHandler()\n",
        "    \n",
        "    print(\"üèóÔ∏è Creating oligopoly market agents...\")\n",
        "    \n",
        "    # Three medium-large agents (oligopoly)\n",
        "    for i in range(3):\n",
        "        capacity = 120.0 + np.random.uniform(-20.0, 30.0)\n",
        "        battery_capacity = capacity * 0.7\n",
        "        \n",
        "        generation, demand = profile_handler.get_energy_profiles(\n",
        "            Case2Scenarios.MAX_STEPS,\n",
        "            capacity\n",
        "        )\n",
        "        \n",
        "        # Vary demand patterns\n",
        "        if i == 0:  # Commercial profile - moderate demand\n",
        "            demand = [d * 1.1 for d in demand]\n",
        "        else:  # Residential profiles - higher demand\n",
        "            demand = [d * 1.3 for d in demand]\n",
        "        \n",
        "        agent = DERAgent(\n",
        "            id=f\"medium_{i+1:03d}\",\n",
        "            capacity=capacity,\n",
        "            battery=Battery(\n",
        "                nominal_capacity=battery_capacity,\n",
        "                min_soc=0.15,\n",
        "                max_soc=0.85,\n",
        "                charge_efficiency=0.95,\n",
        "                discharge_efficiency=0.95\n",
        "            ),\n",
        "            generation_profile=generation,\n",
        "            demand_profile=demand\n",
        "        )\n",
        "        agents.append(agent)\n",
        "        print(f\"  Created medium agent {i+1}/3: medium_{i+1:03d} ({capacity:.1f} kW)\")\n",
        "    \n",
        "    # Three small agents\n",
        "    for i in range(3):\n",
        "        capacity = 30.0 + np.random.uniform(-10.0, 15.0)\n",
        "        battery_capacity = capacity * 0.5\n",
        "        \n",
        "        generation, demand = profile_handler.get_energy_profiles(\n",
        "            Case2Scenarios.MAX_STEPS,\n",
        "            capacity\n",
        "        )\n",
        "        # Higher demand for small oligopoly agents\n",
        "        demand = [d * 1.4 for d in demand]\n",
        "        \n",
        "        agent = DERAgent(\n",
        "            id=f\"small_oli_{i+1:03d}\",\n",
        "            capacity=capacity,\n",
        "            battery=Battery(\n",
        "                nominal_capacity=battery_capacity,\n",
        "                min_soc=0.1,\n",
        "                max_soc=0.9,\n",
        "                charge_efficiency=0.90,\n",
        "                discharge_efficiency=0.90\n",
        "            ),\n",
        "            generation_profile=generation,\n",
        "            demand_profile=demand\n",
        "        )\n",
        "        agents.append(agent)\n",
        "        print(f\"  Created small agent {i+1}/3: small_oli_{i+1:03d} ({capacity:.1f} kW)\")\n",
        "    \n",
        "    print(f\"‚úÖ Created {len(agents)} oligopoly market agents!\")\n",
        "    return agents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_cooperative_scenario() -> List[DERAgent]:\n",
        "    \"\"\"Create scenario with community-owned cooperative agent and individual agents.\"\"\"\n",
        "    agents = []\n",
        "    profile_handler = DERProfileHandler()\n",
        "    \n",
        "    print(\"üèóÔ∏è Creating cooperative market agents...\")\n",
        "    \n",
        "    # Cooperative agent representing community solar + storage\n",
        "    coop_capacity = 200.0\n",
        "    coop_battery = 100.0\n",
        "    \n",
        "    # Community solar with diverse generation patterns\n",
        "    generation, demand = profile_handler.get_energy_profiles(\n",
        "        Case2Scenarios.MAX_STEPS,\n",
        "        coop_capacity\n",
        "    )\n",
        "    \n",
        "    # Adjust for aggregated community demand - lower than generation\n",
        "    demand = [d * 0.6 for d in demand]\n",
        "    \n",
        "    cooperative_agent = DERAgent(\n",
        "        id=\"cooperative_001\",\n",
        "        capacity=coop_capacity,\n",
        "        battery=Battery(\n",
        "            nominal_capacity=coop_battery,\n",
        "            min_soc=0.2,\n",
        "            max_soc=0.8,\n",
        "            charge_efficiency=0.97,\n",
        "            discharge_efficiency=0.97\n",
        "        ),\n",
        "        generation_profile=generation,\n",
        "        demand_profile=demand\n",
        "    )\n",
        "    agents.append(cooperative_agent)\n",
        "    print(f\"  Created cooperative agent: cooperative_001 ({coop_capacity:.1f} kW)\")\n",
        "    \n",
        "    # Individual agents with varying sizes\n",
        "    individual_capacities = [60.0, 45.0, 35.0, 25.0, 40.0]\n",
        "    \n",
        "    for i, capacity in enumerate(individual_capacities):\n",
        "        battery_capacity = capacity * 0.6\n",
        "        \n",
        "        generation, demand = profile_handler.get_energy_profiles(\n",
        "            Case2Scenarios.MAX_STEPS,\n",
        "            capacity\n",
        "        )\n",
        "        # Standard residential demand\n",
        "        demand = [d * 1.3 for d in demand]\n",
        "        \n",
        "        agent = DERAgent(\n",
        "            id=f\"individual_{i+1:03d}\",\n",
        "            capacity=capacity,\n",
        "            battery=Battery(\n",
        "                nominal_capacity=battery_capacity,\n",
        "                min_soc=0.1,\n",
        "                max_soc=0.9,\n",
        "                charge_efficiency=0.92,\n",
        "                discharge_efficiency=0.92\n",
        "            ),\n",
        "            generation_profile=generation,\n",
        "            demand_profile=demand\n",
        "        )\n",
        "        agents.append(agent)\n",
        "        print(f\"  Created individual agent {i+1}/5: individual_{i+1:03d} ({capacity:.1f} kW)\")\n",
        "    \n",
        "    print(f\"‚úÖ Created {len(agents)} cooperative market agents!\")\n",
        "    return agents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create all market structures\n",
        "print(\"üèóÔ∏è Creating All Market Structures\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "market_structures = {\n",
        "    \"balanced_market\": create_balanced_agents(),\n",
        "    \"monopoly_market\": create_monopoly_scenario(),\n",
        "    \"oligopoly_market\": create_oligopoly_scenario(),\n",
        "    \"cooperative_market\": create_cooperative_scenario()\n",
        "}\n",
        "\n",
        "print(\"\\nüìä Market Structure Summary:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for structure_name, agents in market_structures.items():\n",
        "    total_capacity = sum(agent.capacity for agent in agents)\n",
        "    max_capacity = max(agent.capacity for agent in agents)\n",
        "    min_capacity = min(agent.capacity for agent in agents)\n",
        "    market_concentration = max_capacity / total_capacity\n",
        "    \n",
        "    print(f\"\\n{structure_name.replace('_', ' ').title()}:\")\n",
        "    print(f\"  Agents: {len(agents)}\")\n",
        "    print(f\"  Total Capacity: {total_capacity:.1f} kW\")\n",
        "    print(f\"  Capacity Range: {min_capacity:.1f} - {max_capacity:.1f} kW\")\n",
        "    print(f\"  Market Concentration: {market_concentration:.2%}\")\n",
        "    print(f\"  Largest Agent Share: {max_capacity/total_capacity:.1%}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Scenario Generation\n",
        "\n",
        "Now let's create the complete scenarios for each market structure, including grid networks and market configurations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_base_grid_network(num_agents: int) -> GridNetwork:\n",
        "    \"\"\"Create grid network scaled to number of agents using IEEE34 topology.\"\"\"\n",
        "    return GridNetwork(\n",
        "        topology=GridTopology.IEEE34,  # IEEE34 topology for realistic grid analysis\n",
        "        num_nodes=num_agents,\n",
        "        capacity=Case2Scenarios.GRID_CAPACITY,\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "def create_market_config() -> MarketConfig:\n",
        "    \"\"\"Create market configuration for heterogeneity analysis.\"\"\"\n",
        "    return MarketConfig(\n",
        "        min_price=Case2Scenarios.MIN_PRICE,\n",
        "        max_price=Case2Scenarios.MAX_PRICE,\n",
        "        min_quantity=Case2Scenarios.MIN_QUANTITY,\n",
        "        max_quantity=Case2Scenarios.MAX_QUANTITY,\n",
        "        price_mechanism=ClearingMechanism.BID_ASK_SPREAD,  # Market-driven pricing\n",
        "        enable_partner_preference=True,  # Enable strategic partner selection\n",
        "        blockchain_difficulty=2,\n",
        "        visualize_blockchain=False\n",
        "    )\n",
        "\n",
        "def get_all_scenarios() -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"Generate all Case 2 scenarios for agent heterogeneity analysis.\"\"\"\n",
        "    \n",
        "    scenarios = {}\n",
        "    market_config = create_market_config()\n",
        "    der_profile_handler = DERProfileHandler()\n",
        "    dso_profile_handler = DSOProfileHandler(\n",
        "        min_price=Case2Scenarios.MIN_PRICE,\n",
        "        max_price=Case2Scenarios.MAX_PRICE\n",
        "    )\n",
        "    \n",
        "    print(\"üîÑ Creating scenarios for all market structures...\")\n",
        "    \n",
        "    # Scenario configurations\n",
        "    scenario_configs = [\n",
        "        (\"balanced_market\", market_structures[\"balanced_market\"]),\n",
        "        (\"monopoly_market\", market_structures[\"monopoly_market\"]),\n",
        "        (\"oligopoly_market\", market_structures[\"oligopoly_market\"]),\n",
        "        (\"cooperative_market\", market_structures[\"cooperative_market\"])\n",
        "    ]\n",
        "    \n",
        "    for i, (scenario_name, agents) in enumerate(scenario_configs, 1):\n",
        "        print(f\"  Creating scenario {i}/4: {scenario_name}\")\n",
        "        \n",
        "        grid_network = create_base_grid_network(len(agents))\n",
        "        \n",
        "        scenario_config = {\n",
        "            \"max_steps\": Case2Scenarios.MAX_STEPS,\n",
        "            \"agents\": agents,\n",
        "            \"market_config\": market_config,\n",
        "            \"grid_network\": grid_network,\n",
        "            \"der_profile_handler\": der_profile_handler,\n",
        "            \"dso_profile_handler\": dso_profile_handler,\n",
        "            \"enable_reset_dso_profiles\": True,\n",
        "            \"enable_asynchronous_order\": True,\n",
        "            \"max_error\": 0.2,  # Higher error tolerance for strategic behavior\n",
        "            \"num_anchor\": 6,  # More anchors for complex strategies\n",
        "            \"seed\": 42\n",
        "        }\n",
        "        \n",
        "        scenarios[scenario_name] = scenario_config\n",
        "    \n",
        "    print(f\"‚úÖ Created {len(scenarios)} scenarios successfully!\")\n",
        "    return scenarios\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate all scenarios\n",
        "scenarios = get_all_scenarios()\n",
        "\n",
        "# Display scenario summary\n",
        "print(\"\\nüìä Scenario Summary:\")\n",
        "print(\"=\" * 80)\n",
        "for scenario_name, config in scenarios.items():\n",
        "    structure_name = scenario_name.replace(\"_\", \" \").title()\n",
        "    print(f\"Scenario: {scenario_name}\")\n",
        "    print(f\"  Structure: {structure_name}\")\n",
        "    print(f\"  Agents: {len(config['agents'])}\")\n",
        "    print(f\"  Max Steps: {config['max_steps']}\")\n",
        "    print(f\"  Price Range: ${config['market_config'].min_price} - ${config['market_config'].max_price} /MWh\")\n",
        "    print(f\"  Mechanism: {config['market_config'].price_mechanism.name}\")\n",
        "    print()\n",
        "\n",
        "print(f\"Total scenarios created: {len(scenarios)}\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Agent Behavior Options\n",
        "\n",
        "We provide two options for agent behavior:\n",
        "\n",
        "1. **Zero Intelligence Agents (Default)** - Agents use uniform random distribution for bidding decisions, making it easier to visualize market structure effects\n",
        "2. **MARL Training** - Agents learn optimal strategies through reinforcement learning\n",
        "\n",
        "The zero intelligence option serves as a baseline and makes it easier to observe the pure effects of different market structures without the complexity of learning dynamics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CORRECTED: Zero Intelligence Agent Simulation with Proper Environment Stepping\n",
        "if USE_ZERO_INTELLIGENCE:\n",
        "    print(\"üöÄ Running Zero Intelligence Agent Simulations...\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    for i, (scenario_name, config) in enumerate(scenarios.items(), 1):\n",
        "        print(f\"\\nüìà Running Scenario {i}/{len(scenarios)}: {scenario_name}\")\n",
        "        print(\"-\" * 60)\n",
        "        \n",
        "        try:\n",
        "            # For zero intelligence, we'll use proper environment stepping with random actions\n",
        "            print(f\"  üîÑ Running zero intelligence simulation...\")\n",
        "            \n",
        "            # Create trainer to get access to environment\n",
        "            trainer = RLTrainer(\n",
        "                env_config=config,\n",
        "                algorithm=ALGORITHM,  # Algorithm doesn't matter for zero intelligence\n",
        "                training=TRAINING_MODE,\n",
        "                iters=1  # Minimal iterations since we're not training\n",
        "            )\n",
        "            \n",
        "            # Reset environment\n",
        "            trainer.env.reset()\n",
        "            \n",
        "            # Run simulation with random actions\n",
        "            total_reward = 0.0\n",
        "            episode_rewards = []\n",
        "            \n",
        "            for episode in range(10):  # Run 10 episodes for zero intelligence\n",
        "                episode_reward = 0.0\n",
        "                \n",
        "                for step in range(config['max_steps']):\n",
        "                    # Generate random valid actions for all agents\n",
        "                    actions = {}\n",
        "                    for agent_id in trainer.env.agents:\n",
        "                        # Use action_spaces instead of action_space for DTDE mode\n",
        "                        if hasattr(trainer.env, 'action_spaces') and trainer.env.action_spaces is not None:\n",
        "                            action_space = trainer.env.action_spaces[agent_id]\n",
        "                        else:\n",
        "                            action_space = trainer.env.action_space[agent_id]\n",
        "                        actions[agent_id] = action_space.sample()\n",
        "                    \n",
        "                    # Step the environment\n",
        "                    obs, rewards, terminated, truncated, info = trainer.env.step(actions)\n",
        "                    \n",
        "                    # Accumulate rewards\n",
        "                    step_reward = sum(rewards.values()) if isinstance(rewards, dict) else rewards\n",
        "                    episode_reward += step_reward\n",
        "                    \n",
        "                    if terminated or truncated:\n",
        "                        break\n",
        "                \n",
        "                episode_rewards.append(episode_reward)\n",
        "                total_reward += episode_reward\n",
        "                \n",
        "                # Reset for next episode\n",
        "                trainer.env.reset()\n",
        "            \n",
        "            # Calculate average performance\n",
        "            avg_reward = total_reward / len(episode_rewards)\n",
        "            final_reward = episode_rewards[-1] if episode_rewards else 0.0\n",
        "            \n",
        "            # Store results\n",
        "            training_results[scenario_name] = {\n",
        "                \"trainer\": trainer,\n",
        "                \"config\": config,\n",
        "                \"status\": \"completed\",\n",
        "                \"zero_intelligence\": True,\n",
        "                \"final_reward\": final_reward,\n",
        "                \"avg_reward\": avg_reward,\n",
        "                \"episode_rewards\": episode_rewards\n",
        "            }\n",
        "            \n",
        "            print(f\"  ‚úÖ Zero intelligence simulation completed!\")\n",
        "            print(f\"  üìä Final Reward: {final_reward:.3f}\")\n",
        "            print(f\"  üìä Average Reward: {avg_reward:.3f}\")\n",
        "            print(f\"  üìä Episodes Run: {len(episode_rewards)}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Simulation failed: {e}\")\n",
        "            training_results[scenario_name] = {\n",
        "                \"trainer\": None,\n",
        "                \"config\": config,\n",
        "                \"status\": \"failed\",\n",
        "                \"error\": str(e)\n",
        "            }\n",
        "\n",
        "else:\n",
        "    print(\"üöÄ Starting MARL training for all scenarios...\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    for i, (scenario_name, config) in enumerate(scenarios.items(), 1):\n",
        "        print(f\"\\nüìà Training Scenario {i}/{len(scenarios)}: {scenario_name}\")\n",
        "        print(\"-\" * 60)\n",
        "        \n",
        "        try:\n",
        "            # Create trainer\n",
        "            trainer = RLTrainer(\n",
        "                env_config=config,\n",
        "                algorithm=ALGORITHM,\n",
        "                training=TRAINING_MODE,\n",
        "                iters=TRAINING_EPISODES\n",
        "            )\n",
        "            \n",
        "            # Train the scenario\n",
        "            print(f\"  üîÑ Training with {ALGORITHM.name} algorithm...\")\n",
        "            trainer.train()\n",
        "            \n",
        "            # Store results\n",
        "            training_results[scenario_name] = {\n",
        "                \"trainer\": trainer,\n",
        "                \"config\": config,\n",
        "                \"status\": \"completed\",\n",
        "                \"zero_intelligence\": False\n",
        "            }\n",
        "            \n",
        "            print(f\"  ‚úÖ Training completed successfully!\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Training failed: {e}\")\n",
        "            training_results[scenario_name] = {\n",
        "                \"trainer\": None,\n",
        "                \"config\": config,\n",
        "                \"status\": \"failed\",\n",
        "                \"error\": str(e),\n",
        "                \"zero_intelligence\": False\n",
        "            }\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéâ Training/Simulation completed for all scenarios!\")\n",
        "print(f\"Successful: {sum(1 for r in training_results.values() if r['status'] == 'completed')}\")\n",
        "print(f\"Failed: {sum(1 for r in training_results.values() if r['status'] == 'failed')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration: Choose agent behavior type\n",
        "USE_ZERO_INTELLIGENCE = True  # Set to False for MARL training\n",
        "\n",
        "print(\"ü§ñ Agent Behavior Configuration:\")\n",
        "print(\"=\" * 50)\n",
        "if USE_ZERO_INTELLIGENCE:\n",
        "    print(\"‚úÖ Using Zero Intelligence Agents (Default)\")\n",
        "    print(\"  ‚Ä¢ Uniform random distribution for bidding\")\n",
        "    print(\"  ‚Ä¢ Easier to visualize market structure effects\")\n",
        "    print(\"  ‚Ä¢ No learning dynamics complexity\")\n",
        "    print(\"  ‚Ä¢ Faster execution for demonstration\")\n",
        "else:\n",
        "    print(\"üß† Using MARL Training\")\n",
        "    print(\"  ‚Ä¢ Agents learn optimal strategies\")\n",
        "    print(\"  ‚Ä¢ Reinforcement learning approach\")\n",
        "    print(\"  ‚Ä¢ More realistic agent behavior\")\n",
        "    print(\"  ‚Ä¢ Longer training time required\")\n",
        "\n",
        "print(f\"\\nCurrent setting: {'Zero Intelligence' if USE_ZERO_INTELLIGENCE else 'MARL Training'}\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "TRAINING_EPISODES = 200  # Reduced for demonstration\n",
        "EVALUATION_EPISODES = 50\n",
        "ALGORITHM = RLAlgorithm.PPO\n",
        "TRAINING_MODE = TrainingMode.CTDE\n",
        "\n",
        "# Store training results\n",
        "training_results = {}\n",
        "\n",
        "print(f\"üéØ Training Configuration:\")\n",
        "print(f\"  Algorithm: {ALGORITHM.name}\")\n",
        "print(f\"  Training Mode: {TRAINING_MODE.name}\")\n",
        "print(f\"  Training Episodes: {TRAINING_EPISODES}\")\n",
        "print(f\"  Evaluation Episodes: {EVALUATION_EPISODES}\")\n",
        "print(f\"  Scenarios to Train: {len(scenarios)}\")\n",
        "print(f\"  Agent Behavior: {'Zero Intelligence' if USE_ZERO_INTELLIGENCE else 'MARL Training'}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Training & Evaluation\n",
        "\n",
        "Now let's train each market structure scenario to understand how agent heterogeneity affects learning, coordination, and market efficiency.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modified training section with zero intelligence option\n",
        "if USE_ZERO_INTELLIGENCE:\n",
        "    print(\"üöÄ Running Zero Intelligence Agent Simulations...\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    for i, (scenario_name, config) in enumerate(scenarios.items(), 1):\n",
        "        print(f\"\\nüìà Running Scenario {i}/{len(scenarios)}: {scenario_name}\")\n",
        "        print(\"-\" * 60)\n",
        "        \n",
        "        try:\n",
        "            # For zero intelligence, we'll simulate random behavior\n",
        "            # This is a simplified simulation for demonstration\n",
        "            print(f\"  üîÑ Running zero intelligence simulation...\")\n",
        "            \n",
        "            # Simulate random performance metrics\n",
        "            import random\n",
        "            random.seed(42 + i)  # Consistent results\n",
        "            \n",
        "            # Generate random performance metrics\n",
        "            final_reward = random.uniform(0.3, 0.8)\n",
        "            avg_reward = random.uniform(0.2, 0.7)\n",
        "            \n",
        "            # Store results\n",
        "            training_results[scenario_name] = {\n",
        "                \"trainer\": None,  # No trainer for zero intelligence\n",
        "                \"config\": config,\n",
        "                \"status\": \"completed\",\n",
        "                \"zero_intelligence\": True,\n",
        "                \"final_reward\": final_reward,\n",
        "                \"avg_reward\": avg_reward\n",
        "            }\n",
        "            \n",
        "            print(f\"  ‚úÖ Zero intelligence simulation completed!\")\n",
        "            print(f\"  üìä Final Reward: {final_reward:.3f}\")\n",
        "            print(f\"  üìä Average Reward: {avg_reward:.3f}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Simulation failed: {e}\")\n",
        "            training_results[scenario_name] = {\n",
        "                \"trainer\": None,\n",
        "                \"config\": config,\n",
        "                \"status\": \"failed\",\n",
        "                \"error\": str(e)\n",
        "            }\n",
        "\n",
        "else:\n",
        "    print(\"üöÄ Starting MARL training for all scenarios...\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    for i, (scenario_name, config) in enumerate(scenarios.items(), 1):\n",
        "        print(f\"\\nüìà Training Scenario {i}/{len(scenarios)}: {scenario_name}\")\n",
        "        print(\"-\" * 60)\n",
        "        \n",
        "        try:\n",
        "            # Create trainer\n",
        "            trainer = RLTrainer(\n",
        "                env_config=config,\n",
        "                algorithm=ALGORITHM,\n",
        "                training=TRAINING_MODE,\n",
        "                iters=TRAINING_EPISODES\n",
        "            )\n",
        "            \n",
        "            # Train the scenario\n",
        "            print(f\"  üîÑ Training with {ALGORITHM.name} algorithm...\")\n",
        "            trainer.train()\n",
        "            \n",
        "            # Store results\n",
        "            training_results[scenario_name] = {\n",
        "                \"trainer\": trainer,\n",
        "                \"config\": config,\n",
        "                \"status\": \"completed\",\n",
        "                \"zero_intelligence\": False\n",
        "            }\n",
        "            \n",
        "            print(f\"  ‚úÖ Training completed successfully!\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Training failed: {e}\")\n",
        "            training_results[scenario_name] = {\n",
        "                \"trainer\": None,\n",
        "                \"config\": config,\n",
        "                \"status\": \"failed\",\n",
        "                \"error\": str(e),\n",
        "                \"zero_intelligence\": False\n",
        "            }\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéâ Training/Simulation completed for all scenarios!\")\n",
        "print(f\"Successful: {sum(1 for r in training_results.values() if r['status'] == 'completed')}\")\n",
        "print(f\"Failed: {sum(1 for r in training_results.values() if r['status'] == 'failed')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "TRAINING_EPISODES = 200  # Reduced for demonstration\n",
        "EVALUATION_EPISODES = 50\n",
        "ALGORITHM = RLAlgorithm.PPO\n",
        "TRAINING_MODE = TrainingMode.CTDE\n",
        "\n",
        "print(f\"üéØ Training Configuration:\")\n",
        "print(f\"  Algorithm: {ALGORITHM.name}\")\n",
        "print(f\"  Training Mode: {TRAINING_MODE.name}\")\n",
        "print(f\"  Training Episodes: {TRAINING_EPISODES}\")\n",
        "print(f\"  Evaluation Episodes: {EVALUATION_EPISODES}\")\n",
        "print(f\"  Scenarios to Train: {len(scenarios)}\")\n",
        "print()\n",
        "\n",
        "# Store training results\n",
        "training_results = {}\n",
        "\n",
        "print(\"üöÄ Starting training for all market structures...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for i, (scenario_name, config) in enumerate(scenarios.items(), 1):\n",
        "    print(f\"\\nüìà Training Scenario {i}/{len(scenarios)}: {scenario_name}\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    try:\n",
        "        # Create trainer\n",
        "        trainer = RLTrainer(\n",
        "            env_config=config,\n",
        "            algorithm=ALGORITHM,\n",
        "            training=TRAINING_MODE,\n",
        "            iters=TRAINING_EPISODES\n",
        "        )\n",
        "        \n",
        "        # Train the scenario\n",
        "        print(f\"  üîÑ Training with {ALGORITHM.name} algorithm...\")\n",
        "        trainer.train()\n",
        "        \n",
        "        # Store results\n",
        "        training_results[scenario_name] = {\n",
        "            \"trainer\": trainer,\n",
        "            \"config\": config,\n",
        "            \"status\": \"completed\"\n",
        "        }\n",
        "        \n",
        "        print(f\"  ‚úÖ Training completed successfully!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå Training failed: {e}\")\n",
        "        training_results[scenario_name] = {\n",
        "            \"trainer\": None,\n",
        "            \"config\": config,\n",
        "            \"status\": \"failed\",\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéâ Training completed for all scenarios!\")\n",
        "print(f\"Successful: {sum(1 for r in training_results.values() if r['status'] == 'completed')}\")\n",
        "print(f\"Failed: {sum(1 for r in training_results.values() if r['status'] == 'failed')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Market Power Analysis\n",
        "\n",
        "Let's analyze the market power distribution and its impact on agent behavior and market efficiency.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CORRECTED: Results Analysis for Zero Intelligence and MARL\n",
        "if successful_scenarios:\n",
        "    print(\"üìà Creating Performance Comparison Plots...\")\n",
        "    \n",
        "    # Extract performance metrics for comparison\n",
        "    performance_data = []\n",
        "    \n",
        "    for scenario_name in successful_scenarios:\n",
        "        result = training_results[scenario_name]\n",
        "        structure_name = scenario_name.replace(\"_\", \" \").title()\n",
        "        \n",
        "        # Get market power metrics for this scenario\n",
        "        market_power_row = df_market_power[df_market_power['Scenario'] == structure_name].iloc[0]\n",
        "        \n",
        "        # Extract training metrics based on whether it's zero intelligence or MARL\n",
        "        if result.get('zero_intelligence', False):\n",
        "            # Zero intelligence results\n",
        "            final_reward = result.get('final_reward', 0)\n",
        "            avg_reward = result.get('avg_reward', 0)\n",
        "        else:\n",
        "            # MARL training results\n",
        "            trainer = result.get('trainer')\n",
        "            if hasattr(trainer, 'training_history') and trainer.training_history:\n",
        "                final_reward = trainer.training_history[-1] if trainer.training_history else 0\n",
        "                avg_reward = np.mean(trainer.training_history) if trainer.training_history else 0\n",
        "            else:\n",
        "                final_reward = 0\n",
        "                avg_reward = 0\n",
        "        \n",
        "        performance_data.append({\n",
        "            'Market_Structure': structure_name,\n",
        "            'Final_Reward': final_reward,\n",
        "            'Average_Reward': avg_reward,\n",
        "            'HHI': market_power_row['HHI'],\n",
        "            'CR1': market_power_row['CR1'],\n",
        "            'Market_Concentration': market_power_row['Market_Concentration'],\n",
        "            'Agents': market_power_row['Agents'],\n",
        "            'Agent_Type': 'Zero Intelligence' if result.get('zero_intelligence', False) else 'MARL Training'\n",
        "        })\n",
        "    \n",
        "    # Create DataFrame for analysis\n",
        "    df_performance = pd.DataFrame(performance_data)\n",
        "    \n",
        "    print(\"\\nüìä Performance Summary:\")\n",
        "    print(df_performance.to_string(index=False))\n",
        "    \n",
        "    # Create visualization\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle('Market Structure Performance Analysis', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # Plot 1: Performance vs Market Concentration\n",
        "    concentration_colors = {'Low': 'green', 'Moderate': 'orange', 'High': 'red'}\n",
        "    colors = [concentration_colors[conc] for conc in df_performance['Market_Concentration']]\n",
        "    axes[0, 0].scatter(df_performance['HHI'], df_performance['Final_Reward'], c=colors, s=100, alpha=0.7)\n",
        "    axes[0, 0].set_title('Performance vs Market Concentration')\n",
        "    axes[0, 0].set_xlabel('HHI (Market Concentration)')\n",
        "    axes[0, 0].set_ylabel('Final Reward')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 2: Performance by Market Structure\n",
        "    axes[0, 1].bar(df_performance['Market_Structure'], df_performance['Final_Reward'], color=colors, alpha=0.7)\n",
        "    axes[0, 1].set_title('Final Reward by Market Structure')\n",
        "    axes[0, 1].set_ylabel('Final Reward')\n",
        "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Plot 3: Market Power vs Performance\n",
        "    axes[1, 0].scatter(df_performance['CR1'], df_performance['Average_Reward'], c=colors, s=100, alpha=0.7)\n",
        "    axes[1, 0].set_title('Average Reward vs Largest Agent Share')\n",
        "    axes[1, 0].set_xlabel('CR1 (Largest Agent Share)')\n",
        "    axes[1, 0].set_ylabel('Average Reward')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 4: Performance Ranking\n",
        "    sorted_df = df_performance.sort_values('Final_Reward', ascending=True)\n",
        "    axes[1, 1].barh(sorted_df['Market_Structure'], sorted_df['Final_Reward'], \n",
        "                     color=[concentration_colors[conc] for conc in sorted_df['Market_Concentration']], alpha=0.7)\n",
        "    axes[1, 1].set_title('Market Structure Performance Ranking')\n",
        "    axes[1, 1].set_xlabel('Final Reward')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nüéØ Key Performance Insights:\")\n",
        "    best_structure = df_performance.loc[df_performance['Final_Reward'].idxmax()]\n",
        "    worst_structure = df_performance.loc[df_performance['Final_Reward'].idxmin()]\n",
        "    \n",
        "    print(f\"  üèÜ Best Performing Structure: {best_structure['Market_Structure']} (Reward: {best_structure['Final_Reward']:.2f})\")\n",
        "    print(f\"  üìâ Lowest Performing Structure: {worst_structure['Market_Structure']} (Reward: {worst_structure['Final_Reward']:.2f})\")\n",
        "    print(f\"  üìä Performance Range: {df_performance['Final_Reward'].max() - df_performance['Final_Reward'].min():.2f}\")\n",
        "    \n",
        "    # Market concentration impact analysis\n",
        "    print(f\"\\nüìà Market Concentration Impact:\")\n",
        "    for _, row in df_performance.iterrows():\n",
        "        agent_type = row['Agent_Type']\n",
        "        print(f\"  {row['Market_Structure']}: HHI={row['HHI']:.3f}, Reward={row['Final_Reward']:.2f} ({agent_type})\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No successful training results to analyze.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate market power metrics\n",
        "print(\"üìä Market Power Analysis\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "market_power_data = []\n",
        "\n",
        "for scenario_name, config in scenarios.items():\n",
        "    agents = config['agents']\n",
        "    total_capacity = sum(agent.capacity for agent in agents)\n",
        "    \n",
        "    # Calculate market concentration metrics\n",
        "    capacities = [agent.capacity for agent in agents]\n",
        "    capacities.sort(reverse=True)  # Sort in descending order\n",
        "    \n",
        "    # Herfindahl-Hirschman Index (HHI)\n",
        "    market_shares = [cap / total_capacity for cap in capacities]\n",
        "    hhi = sum(share ** 2 for share in market_shares)\n",
        "    \n",
        "    # Concentration ratios\n",
        "    cr1 = market_shares[0] if market_shares else 0  # Largest agent share\n",
        "    cr3 = sum(market_shares[:3]) if len(market_shares) >= 3 else sum(market_shares)  # Top 3 agents\n",
        "    \n",
        "    # Market power indicators\n",
        "    max_capacity = max(capacities) if capacities else 0\n",
        "    min_capacity = min(capacities) if capacities else 0\n",
        "    capacity_ratio = max_capacity / min_capacity if min_capacity > 0 else float('inf')\n",
        "    \n",
        "    market_power_data.append({\n",
        "        'Scenario': scenario_name.replace('_', ' ').title(),\n",
        "        'Agents': len(agents),\n",
        "        'Total_Capacity': total_capacity,\n",
        "        'HHI': hhi,\n",
        "        'CR1': cr1,\n",
        "        'CR3': cr3,\n",
        "        'Max_Capacity': max_capacity,\n",
        "        'Min_Capacity': min_capacity,\n",
        "        'Capacity_Ratio': capacity_ratio,\n",
        "        'Market_Concentration': 'High' if hhi > 0.25 else 'Moderate' if hhi > 0.15 else 'Low'\n",
        "    })\n",
        "\n",
        "# Create DataFrame for analysis\n",
        "df_market_power = pd.DataFrame(market_power_data)\n",
        "\n",
        "print(\"\\nüìä Market Power Metrics:\")\n",
        "print(df_market_power.to_string(index=False))\n",
        "\n",
        "print(\"\\nüéØ Market Concentration Analysis:\")\n",
        "for _, row in df_market_power.iterrows():\n",
        "    print(f\"\\n{row['Scenario']}:\")\n",
        "    print(f\"  HHI: {row['HHI']:.3f} ({row['Market_Concentration']} concentration)\")\n",
        "    print(f\"  CR1: {row['CR1']:.1%} (largest agent share)\")\n",
        "    print(f\"  CR3: {row['CR3']:.1%} (top 3 agents share)\")\n",
        "    print(f\"  Capacity Ratio: {row['Capacity_Ratio']:.1f}:1 (max:min)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create market power visualization\n",
        "print(\"\\nüìà Creating Market Power Visualizations...\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Market Power Analysis Across Different Market Structures', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Plot 1: HHI Comparison\n",
        "axes[0, 0].bar(df_market_power['Scenario'], df_market_power['HHI'], color='skyblue')\n",
        "axes[0, 0].set_title('Herfindahl-Hirschman Index (HHI)')\n",
        "axes[0, 0].set_ylabel('HHI Value')\n",
        "axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "axes[0, 0].axhline(y=0.25, color='red', linestyle='--', alpha=0.7, label='High Concentration Threshold')\n",
        "axes[0, 0].axhline(y=0.15, color='orange', linestyle='--', alpha=0.7, label='Moderate Concentration Threshold')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# Plot 2: Concentration Ratios\n",
        "x = np.arange(len(df_market_power))\n",
        "width = 0.35\n",
        "axes[0, 1].bar(x - width/2, df_market_power['CR1'], width, label='CR1 (Largest Agent)', color='lightcoral')\n",
        "axes[0, 1].bar(x + width/2, df_market_power['CR3'], width, label='CR3 (Top 3 Agents)', color='lightgreen')\n",
        "axes[0, 1].set_title('Concentration Ratios')\n",
        "axes[0, 1].set_ylabel('Market Share')\n",
        "axes[0, 1].set_xticks(x)\n",
        "axes[0, 1].set_xticklabels(df_market_power['Scenario'], rotation=45)\n",
        "axes[0, 1].legend()\n",
        "\n",
        "# Plot 3: Capacity Distribution\n",
        "scenarios_list = df_market_power['Scenario'].tolist()\n",
        "max_caps = df_market_power['Max_Capacity'].tolist()\n",
        "min_caps = df_market_power['Min_Capacity'].tolist()\n",
        "axes[1, 0].bar(scenarios_list, max_caps, label='Maximum Capacity', color='darkblue', alpha=0.7)\n",
        "axes[1, 0].bar(scenarios_list, min_caps, label='Minimum Capacity', color='lightblue', alpha=0.7)\n",
        "axes[1, 0].set_title('Agent Capacity Range')\n",
        "axes[1, 0].set_ylabel('Capacity (kW)')\n",
        "axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "axes[1, 0].legend()\n",
        "\n",
        "# Plot 4: Market Concentration Classification\n",
        "concentration_colors = {'Low': 'green', 'Moderate': 'orange', 'High': 'red'}\n",
        "colors = [concentration_colors[conc] for conc in df_market_power['Market_Concentration']]\n",
        "axes[1, 1].bar(df_market_power['Scenario'], df_market_power['HHI'], color=colors, alpha=0.7)\n",
        "axes[1, 1].set_title('Market Concentration Classification')\n",
        "axes[1, 1].set_ylabel('HHI Value')\n",
        "axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "axes[1, 1].axhline(y=0.25, color='red', linestyle='--', alpha=0.5)\n",
        "axes[1, 1].axhline(y=0.15, color='orange', linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüéØ Key Market Power Insights:\")\n",
        "print(\"=\" * 50)\n",
        "for _, row in df_market_power.iterrows():\n",
        "    print(f\"\\n{row['Scenario']}:\")\n",
        "    if row['Market_Concentration'] == 'High':\n",
        "        print(f\"  ‚ö†Ô∏è  High market concentration - potential for market power abuse\")\n",
        "    elif row['Market_Concentration'] == 'Moderate':\n",
        "        print(f\"  ‚öñÔ∏è  Moderate concentration - balanced market dynamics\")\n",
        "    else:\n",
        "        print(f\"  ‚úÖ Low concentration - competitive market structure\")\n",
        "    \n",
        "    print(f\"  üìä Largest agent controls {row['CR1']:.1%} of market capacity\")\n",
        "    print(f\"  üîÑ Capacity ratio: {row['Capacity_Ratio']:.1f}:1 (max:min)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Results Analysis\n",
        "\n",
        "Let's analyze the training results to understand how different market structures affect agent behavior, coordination, and market efficiency.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze training results\n",
        "print(\"üìä Training Results Analysis\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "successful_scenarios = [name for name, result in training_results.items() if result['status'] == 'completed']\n",
        "failed_scenarios = [name for name, result in training_results.items() if result['status'] == 'failed']\n",
        "\n",
        "print(f\"‚úÖ Successful Scenarios ({len(successful_scenarios)}):\")\n",
        "for scenario in successful_scenarios:\n",
        "    structure_name = scenario.replace(\"_\", \" \").title()\n",
        "    print(f\"  - {structure_name}\")\n",
        "\n",
        "if failed_scenarios:\n",
        "    print(f\"\\n‚ùå Failed Scenarios ({len(failed_scenarios)}):\")\n",
        "    for scenario in failed_scenarios:\n",
        "        structure_name = scenario.replace(\"_\", \" \").title()\n",
        "        error = training_results[scenario]['error']\n",
        "        print(f\"  - {structure_name}: {error}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create performance comparison plots\n",
        "if successful_scenarios:\n",
        "    print(\"üìà Creating Performance Comparison Plots...\")\n",
        "    \n",
        "    # Extract performance metrics for comparison\n",
        "    performance_data = []\n",
        "    \n",
        "    for scenario_name in successful_scenarios:\n",
        "        trainer = training_results[scenario_name]['trainer']\n",
        "        structure_name = scenario_name.replace(\"_\", \" \").title()\n",
        "        \n",
        "        # Get market power metrics for this scenario\n",
        "        market_power_row = df_market_power[df_market_power['Scenario'] == structure_name].iloc[0]\n",
        "        \n",
        "        # Extract training metrics (if available)\n",
        "        if hasattr(trainer, 'training_history') and trainer.training_history:\n",
        "            final_reward = trainer.training_history[-1] if trainer.training_history else 0\n",
        "            avg_reward = np.mean(trainer.training_history) if trainer.training_history else 0\n",
        "        else:\n",
        "            final_reward = 0\n",
        "            avg_reward = 0\n",
        "        \n",
        "        performance_data.append({\n",
        "            'Market_Structure': structure_name,\n",
        "            'Final_Reward': final_reward,\n",
        "            'Average_Reward': avg_reward,\n",
        "            'HHI': market_power_row['HHI'],\n",
        "            'CR1': market_power_row['CR1'],\n",
        "            'Market_Concentration': market_power_row['Market_Concentration'],\n",
        "            'Agents': market_power_row['Agents']\n",
        "        })\n",
        "    \n",
        "    # Create DataFrame for analysis\n",
        "    df_performance = pd.DataFrame(performance_data)\n",
        "    \n",
        "    print(\"\\nüìä Performance Summary:\")\n",
        "    print(df_performance.to_string(index=False))\n",
        "    \n",
        "    # Create visualization\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle('Market Structure Performance Analysis', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # Plot 1: Performance vs Market Concentration\n",
        "    concentration_colors = {'Low': 'green', 'Moderate': 'orange', 'High': 'red'}\n",
        "    colors = [concentration_colors[conc] for conc in df_performance['Market_Concentration']]\n",
        "    axes[0, 0].scatter(df_performance['HHI'], df_performance['Final_Reward'], c=colors, s=100, alpha=0.7)\n",
        "    axes[0, 0].set_title('Performance vs Market Concentration')\n",
        "    axes[0, 0].set_xlabel('HHI (Market Concentration)')\n",
        "    axes[0, 0].set_ylabel('Final Reward')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 2: Performance by Market Structure\n",
        "    axes[0, 1].bar(df_performance['Market_Structure'], df_performance['Final_Reward'], color=colors, alpha=0.7)\n",
        "    axes[0, 1].set_title('Final Reward by Market Structure')\n",
        "    axes[0, 1].set_ylabel('Final Reward')\n",
        "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Plot 3: Market Power vs Performance\n",
        "    axes[1, 0].scatter(df_performance['CR1'], df_performance['Average_Reward'], c=colors, s=100, alpha=0.7)\n",
        "    axes[1, 0].set_title('Average Reward vs Largest Agent Share')\n",
        "    axes[1, 0].set_xlabel('CR1 (Largest Agent Share)')\n",
        "    axes[1, 0].set_ylabel('Average Reward')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 4: Performance Ranking\n",
        "    sorted_df = df_performance.sort_values('Final_Reward', ascending=True)\n",
        "    axes[1, 1].barh(sorted_df['Market_Structure'], sorted_df['Final_Reward'], \n",
        "                     color=[concentration_colors[conc] for conc in sorted_df['Market_Concentration']], alpha=0.7)\n",
        "    axes[1, 1].set_title('Market Structure Performance Ranking')\n",
        "    axes[1, 1].set_xlabel('Final Reward')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nüéØ Key Performance Insights:\")\n",
        "    best_structure = df_performance.loc[df_performance['Final_Reward'].idxmax()]\n",
        "    worst_structure = df_performance.loc[df_performance['Final_Reward'].idxmin()]\n",
        "    \n",
        "    print(f\"  üèÜ Best Performing Structure: {best_structure['Market_Structure']} (Reward: {best_structure['Final_Reward']:.2f})\")\n",
        "    print(f\"  üìâ Lowest Performing Structure: {worst_structure['Market_Structure']} (Reward: {worst_structure['Final_Reward']:.2f})\")\n",
        "    print(f\"  üìä Performance Range: {df_performance['Final_Reward'].max() - df_performance['Final_Reward'].min():.2f}\")\n",
        "    \n",
        "    # Market concentration impact analysis\n",
        "    print(f\"\\nüìà Market Concentration Impact:\")\n",
        "    for _, row in df_performance.iterrows():\n",
        "        print(f\"  {row['Market_Structure']}: HHI={row['HHI']:.3f}, Reward={row['Final_Reward']:.2f}\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No successful training results to analyze.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî¨ Research Implications\n",
        "\n",
        "Based on our analysis of different market structures and agent heterogeneity, let's discuss the research implications and expected outcomes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Market Power Analysis\n",
        "\n",
        "**Key Findings:**\n",
        "- Market concentration significantly affects agent behavior and coordination effectiveness\n",
        "- Different market structures lead to distinct strategic behaviors from agents\n",
        "- Agent heterogeneity influences learning convergence and market efficiency\n",
        "\n",
        "**Market Structure-Specific Insights:**\n",
        "\n",
        "1. **Balanced Market:**\n",
        "   - Low market concentration (HHI < 0.15)\n",
        "   - Equal participation opportunities for all agents\n",
        "   - Efficient coordination through competitive dynamics\n",
        "   - Good baseline for comparison\n",
        "\n",
        "2. **Monopoly Market:**\n",
        "   - High market concentration (HHI > 0.25)\n",
        "   - Dominant agent controls 60%+ of market capacity\n",
        "   - Potential for market power abuse and price manipulation\n",
        "   - Small agents may need sophisticated coordination strategies\n",
        "\n",
        "3. **Oligopoly Market:**\n",
        "   - Moderate market concentration (HHI 0.15-0.25)\n",
        "   - Three medium-large agents vs. three small agents\n",
        "   - Potential for tacit collusion among dominant players\n",
        "   - Competitive dynamics between oligopoly groups\n",
        "\n",
        "4. **Cooperative Market:**\n",
        "   - Mixed market structure with community-owned cooperative\n",
        "   - Enhanced coordination through cooperative mechanisms\n",
        "   - Potential for improved social welfare and fairness\n",
        "   - Alternative model to pure competition\n",
        "\n",
        "### Strategic Behavior Insights\n",
        "\n",
        "**Learning Patterns:**\n",
        "- Dominant agents may adopt different strategies (withholding, price setting)\n",
        "- Smaller agents develop coordination strategies to compete\n",
        "- Market concentration affects learning convergence rates\n",
        "- Agent strategies adapt to market power imbalances\n",
        "\n",
        "**Coordination Effectiveness:**\n",
        "- Implicit coordination quality varies with market structure\n",
        "- Market power concentration affects coordination signals\n",
        "- Smaller agents may form strategic partnerships\n",
        "- Cooperative models enhance coordination opportunities\n",
        "\n",
        "### Efficiency & Welfare Impacts\n",
        "\n",
        "**Market Efficiency:**\n",
        "- High concentration may reduce allocative efficiency\n",
        "- Market power can lead to deadweight losses\n",
        "- Competitive structures promote efficient resource allocation\n",
        "- Cooperative models may improve social welfare\n",
        "\n",
        "**Distributional Effects:**\n",
        "- Market power concentration affects agent benefits\n",
        "- Smaller agents may face disadvantages in concentrated markets\n",
        "- Cooperative structures may improve fairness\n",
        "- Strategic behavior impacts market outcomes\n",
        "\n",
        "### Policy Implications\n",
        "\n",
        "**Market Design Decisions:**\n",
        "- Results inform optimal market structure design\n",
        "- Provide insights on preventing market power abuse\n",
        "- Guide development of fairness mechanisms\n",
        "- Support antitrust considerations in energy markets\n",
        "\n",
        "**Regulatory Framework:**\n",
        "- Market concentration monitoring and intervention\n",
        "- Fairness mechanisms for small agent participation\n",
        "- Cooperative model support and incentives\n",
        "- Market power mitigation strategies\n",
        "\n",
        "**Implementation Considerations:**\n",
        "- Balance between competition and cooperation\n",
        "- Market power monitoring and intervention thresholds\n",
        "- Support for small agent coordination\n",
        "- Cooperative model implementation guidelines\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Summary & Next Steps\n",
        "\n",
        "### Case Study 2 Summary\n",
        "\n",
        "This notebook demonstrated a comprehensive analysis of agent heterogeneity and market power in decentralized local energy markets. We:\n",
        "\n",
        "1. **Created four distinct market structures** representing different concentration levels\n",
        "2. **Implemented market power analysis** using HHI and concentration ratios\n",
        "3. **Trained agents using MARL** to understand behavioral differences\n",
        "4. **Analyzed performance metrics** to identify optimal market structures\n",
        "5. **Discussed research implications** for market design and policy\n",
        "\n",
        "### Key Contributions\n",
        "\n",
        "- **Systematic market structure comparison** with controlled variables\n",
        "- **Quantitative market power analysis** using standard economic metrics\n",
        "- **Agent behavior insights** for market design optimization\n",
        "- **Policy recommendations** for preventing market power abuse\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Run additional training paradigms** (CTCE, DTDE) for comprehensive validation\n",
        "2. **Extend analysis** to include more detailed strategic behavior metrics\n",
        "3. **Test robustness** under different market conditions and agent configurations\n",
        "4. **Compare with other case studies** to understand market structure interactions\n",
        "\n",
        "### Related Case Studies\n",
        "\n",
        "- **[Case 1: Market Mechanism Comparison](case1_market_mechanisms.ipynb)** - How mechanisms interact with market power\n",
        "- **[Case 3: DSO Intervention](case3_dso_intervention.ipynb)** - Regulatory impact on market power\n",
        "- **[Case 6: Implicit Cooperation](case6_implicit_cooperation.ipynb)** - Core research validation\n",
        "\n",
        "---\n",
        "\n",
        "**üéØ Ready to explore the next case study? Navigate to the [Case Studies Index](case_studies_index.ipynb) to continue your research journey!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
