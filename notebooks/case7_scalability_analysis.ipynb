{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Case Study 7: Scalability Analysis - Computational Time & Performance\n",
        "\n",
        "This notebook conducts a formal quantitative scalability analysis by executing simulations with increasing agent populations to assess computational time and analyze the impact of agent count on market KPIs.\n",
        "\n",
        "## üéØ Objectives\n",
        "\n",
        "1. **Computational Time Analysis**: Measure training time across different agent populations\n",
        "2. **Training Paradigm Comparison**: Compare CTCE, CTDE, and DTDE training modes\n",
        "3. **Algorithm Comparison**: Evaluate PPO, APPO, and SAC algorithms\n",
        "4. **KPI Impact Analysis**: Assess how agent count affects market performance metrics\n",
        "5. **Scalability Limits**: Identify computational bottlenecks and scalability thresholds\n",
        "\n",
        "## üìã Table of Contents\n",
        "\n",
        "1. [Setup & Imports](#setup--imports)\n",
        "2. [Configuration](#configuration)\n",
        "3. [Agent Population Scenarios](#agent-population-scenarios)\n",
        "4. [Scalability Test Execution](#scalability-test-execution)\n",
        "5. [Computational Time Analysis](#computational-time-analysis)\n",
        "6. [KPI Impact Analysis](#kpi-impact-analysis)\n",
        "7. [Results Summary](#results-summary)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üõ†Ô∏è Setup & Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Tuple\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ Imports successful!\")\n",
        "print(f\"üìÅ Project root: {project_root}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import project-specific modules\n",
        "try:\n",
        "    from src.agent.battery import Battery\n",
        "    from src.agent.der import DERAgent\n",
        "    from src.grid.network import GridNetwork, GridTopology\n",
        "    from src.market.matching import MarketConfig\n",
        "    from src.market.mechanism import ClearingMechanism\n",
        "    from src.profile.der import DERProfileHandler\n",
        "    from src.profile.dso import DSOProfileHandler\n",
        "    from src.environment.train import RLTrainer, TrainingMode, RLAlgorithm\n",
        "    \n",
        "    print(\"‚úÖ Project modules imported successfully!\")\n",
        "    \n",
        "    # Display available training modes and algorithms\n",
        "    print(\"\\nüìã Available Training Modes:\")\n",
        "    for mode in TrainingMode:\n",
        "        print(f\"  - {mode.name}: {mode.value}\")\n",
        "    \n",
        "    print(\"\\nüìã Available Algorithms:\")\n",
        "    for algo in RLAlgorithm:\n",
        "        print(f\"  - {algo.name}: {algo.value}\")\n",
        "        \n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Error importing project modules: {e}\")\n",
        "    print(\"Please ensure you're running this notebook from the correct directory\")\n",
        "    print(\"and that all dependencies are installed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ScalabilityConfig:\n",
        "    \"\"\"Configuration for scalability analysis.\"\"\"\n",
        "    \n",
        "    # Agent population sizes to test\n",
        "    AGENT_POPULATIONS = [1, 5, 10, 20, 50, 100]  # Can add more: 200, 500, 1000\n",
        "    \n",
        "    # Training parameters (reduced for scalability testing)\n",
        "    TRAINING_EPISODES = 50  # Reduced for faster scalability testing\n",
        "    EVALUATION_EPISODES = 10\n",
        "    MAX_STEPS = 24  # 24-hour simulation\n",
        "    \n",
        "    # Grid configuration\n",
        "    GRID_CAPACITY = 5000.0  # kW (scaled for larger populations)\n",
        "    GRID_TOPOLOGY = GridTopology.MESH  # Mesh topology for scalability\n",
        "    \n",
        "    # Market parameters\n",
        "    MIN_PRICE = 40.0  # $/MWh\n",
        "    MAX_PRICE = 240.0  # $/MWh\n",
        "    MIN_QUANTITY = 0.1  # kWh\n",
        "    MAX_QUANTITY = 200.0  # kWh\n",
        "    \n",
        "    # Training modes and algorithms to test\n",
        "    TRAINING_MODES = [TrainingMode.CTCE, TrainingMode.CTDE, TrainingMode.DTDE]\n",
        "    ALGORITHMS = [RLAlgorithm.PPO, RLAlgorithm.APPO, RLAlgorithm.SAC]\n",
        "    \n",
        "    # Results storage\n",
        "    RESULTS_DIR = Path(\"scalability_results\")\n",
        "    RESULTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Display configuration\n",
        "print(\"üìä Scalability Analysis Configuration:\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"  Agent Populations: {ScalabilityConfig.AGENT_POPULATIONS}\")\n",
        "print(f\"  Training Episodes: {ScalabilityConfig.TRAINING_EPISODES}\")\n",
        "print(f\"  Evaluation Episodes: {ScalabilityConfig.EVALUATION_EPISODES}\")\n",
        "print(f\"  Grid Capacity: {ScalabilityConfig.GRID_CAPACITY} kW\")\n",
        "print(f\"  Grid Topology: {ScalabilityConfig.GRID_TOPOLOGY.value}\")\n",
        "print(f\"  Training Modes: {[m.name for m in ScalabilityConfig.TRAINING_MODES]}\")\n",
        "print(f\"  Algorithms: {[a.name for a in ScalabilityConfig.ALGORITHMS]}\")\n",
        "print(f\"  Total Test Combinations: {len(ScalabilityConfig.AGENT_POPULATIONS) * len(ScalabilityConfig.TRAINING_MODES) * len(ScalabilityConfig.ALGORITHMS)}\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üë• Agent Population Scenarios\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_agents_for_population(num_agents: int, seed: int = 42) -> List[DERAgent]:\n",
        "    \"\"\"Create a population of agents for scalability testing.\n",
        "    \n",
        "    Args:\n",
        "        num_agents: Number of agents to create\n",
        "        seed: Random seed for reproducibility\n",
        "        \n",
        "    Returns:\n",
        "        List of DERAgent objects\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    agents = []\n",
        "    profile_handler = DERProfileHandler()\n",
        "    \n",
        "    print(f\"  Creating {num_agents} agents...\")\n",
        "    \n",
        "    for i in range(num_agents):\n",
        "        # Vary agent capacities for diversity\n",
        "        capacity = np.random.uniform(50.0, 150.0)\n",
        "        battery_capacity = capacity * np.random.uniform(0.5, 1.0)\n",
        "        \n",
        "        # Generate profiles\n",
        "        generation, demand = profile_handler.get_energy_profiles(\n",
        "            ScalabilityConfig.MAX_STEPS,\n",
        "            capacity\n",
        "        )\n",
        "        \n",
        "        agent = DERAgent(\n",
        "            id=f\"agent_{i:04d}\",\n",
        "            capacity=capacity,\n",
        "            battery=Battery(\n",
        "                nominal_capacity=battery_capacity,\n",
        "                min_soc=0.1,\n",
        "                max_soc=0.9,\n",
        "                charge_efficiency=0.95,\n",
        "                discharge_efficiency=0.95\n",
        "            ),\n",
        "            generation_profile=generation,\n",
        "            demand_profile=demand\n",
        "        )\n",
        "        agents.append(agent)\n",
        "    \n",
        "    return agents\n",
        "\n",
        "def create_scenario_config(num_agents: int) -> Dict[str, Any]:\n",
        "    \"\"\"Create environment configuration for a given number of agents.\n",
        "    \n",
        "    Args:\n",
        "        num_agents: Number of agents in the scenario\n",
        "        \n",
        "    Returns:\n",
        "        Environment configuration dictionary\n",
        "    \"\"\"\n",
        "    agents = create_agents_for_population(num_agents)\n",
        "    \n",
        "    grid_network = GridNetwork(\n",
        "        topology=ScalabilityConfig.GRID_TOPOLOGY,\n",
        "        num_nodes=num_agents,\n",
        "        capacity=ScalabilityConfig.GRID_CAPACITY,\n",
        "        seed=42\n",
        "    )\n",
        "    \n",
        "    grid_network.assign_agents_to_graph(agents)\n",
        "    \n",
        "    market_config = MarketConfig(\n",
        "        min_price=ScalabilityConfig.MIN_PRICE,\n",
        "        max_price=ScalabilityConfig.MAX_PRICE,\n",
        "        min_quantity=ScalabilityConfig.MIN_QUANTITY,\n",
        "        max_quantity=ScalabilityConfig.MAX_QUANTITY,\n",
        "        price_mechanism=ClearingMechanism.AVERAGE,\n",
        "        enable_partner_preference=False,\n",
        "        blockchain_difficulty=1,\n",
        "        visualize_blockchain=False\n",
        "    )\n",
        "    \n",
        "    der_profile_handler = DERProfileHandler()\n",
        "    dso_profile_handler = DSOProfileHandler(\n",
        "        min_price=ScalabilityConfig.MIN_PRICE,\n",
        "        max_price=ScalabilityConfig.MAX_PRICE\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        \"max_steps\": ScalabilityConfig.MAX_STEPS,\n",
        "        \"agents\": agents,\n",
        "        \"market_config\": market_config,\n",
        "        \"grid_network\": grid_network,\n",
        "        \"der_profile_handler\": der_profile_handler,\n",
        "        \"dso_profile_handler\": dso_profile_handler,\n",
        "        \"enable_reset_dso_profiles\": True,\n",
        "        \"enable_asynchronous_order\": True,\n",
        "        \"max_error\": 0.15,\n",
        "        \"num_anchor\": 8,\n",
        "        \"seed\": 42\n",
        "    }\n",
        "\n",
        "# Test agent creation\n",
        "print(\"üß™ Testing agent creation:\")\n",
        "test_agents = create_agents_for_population(5)\n",
        "print(f\"‚úÖ Created {len(test_agents)} test agents successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_scalability_test(num_agents: int, \n",
        "                        training_mode: TrainingMode,\n",
        "                        algorithm: RLAlgorithm,\n",
        "                        verbose: bool = True) -> Dict[str, Any]:\n",
        "    \"\"\"Run a single scalability test and measure computational time.\n",
        "    \n",
        "    Args:\n",
        "        num_agents: Number of agents\n",
        "        training_mode: Training mode (CTCE, CTDE, DTDE)\n",
        "        algorithm: RL algorithm (PPO, APPO, SAC)\n",
        "        verbose: Whether to print progress\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary with test results including timing and KPIs\n",
        "    \"\"\"\n",
        "    if verbose:\n",
        "        print(f\"\\nüîÑ Testing: {num_agents} agents, {training_mode.name}, {algorithm.name}\")\n",
        "    \n",
        "    # Create scenario configuration\n",
        "    env_config = create_scenario_config(num_agents)\n",
        "    \n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    \n",
        "    try:\n",
        "        # Create trainer\n",
        "        trainer = RLTrainer(\n",
        "            env_config=env_config,\n",
        "            algorithm=algorithm,\n",
        "            training=training_mode,\n",
        "            iters=ScalabilityConfig.TRAINING_EPISODES,\n",
        "            cpus=1,\n",
        "            gpus=0\n",
        "        )\n",
        "        \n",
        "        # Train\n",
        "        trainer.train()\n",
        "        \n",
        "        training_time = time.time() - start_time\n",
        "        \n",
        "        # Calculate time per agent and per episode\n",
        "        time_per_agent = training_time / num_agents if num_agents > 0 else 0\n",
        "        time_per_episode = training_time / ScalabilityConfig.TRAINING_EPISODES if ScalabilityConfig.TRAINING_EPISODES > 0 else 0\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"  ‚úÖ Completed in {training_time:.2f}s ({time_per_agent:.3f}s/agent, {time_per_episode:.3f}s/episode)\")\n",
        "        \n",
        "        return {\n",
        "            \"num_agents\": num_agents,\n",
        "            \"training_mode\": training_mode.name,\n",
        "            \"algorithm\": algorithm.name,\n",
        "            \"training_time\": training_time,\n",
        "            \"time_per_agent\": time_per_agent,\n",
        "            \"time_per_episode\": time_per_episode,\n",
        "            \"status\": \"success\",\n",
        "            \"trainer\": trainer\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        training_time = time.time() - start_time\n",
        "        if verbose:\n",
        "            print(f\"  ‚ùå Failed after {training_time:.2f}s: {str(e)}\")\n",
        "        \n",
        "        return {\n",
        "            \"num_agents\": num_agents,\n",
        "            \"training_mode\": training_mode.name,\n",
        "            \"algorithm\": algorithm.name,\n",
        "            \"training_time\": training_time,\n",
        "            \"time_per_agent\": 0,\n",
        "            \"time_per_episode\": 0,\n",
        "            \"status\": \"failed\",\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "# Run a quick test\n",
        "print(\"üß™ Running quick scalability test (1 agent, PPO, CTDE)...\")\n",
        "test_result = run_scalability_test(1, TrainingMode.CTDE, RLAlgorithm.PPO, verbose=True)\n",
        "print(f\"\\n‚úÖ Test completed: {test_result['status']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run full scalability analysis\n",
        "print(\"üöÄ Starting Full Scalability Analysis\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Total test combinations: {len(ScalabilityConfig.AGENT_POPULATIONS) * len(ScalabilityConfig.TRAINING_MODES) * len(ScalabilityConfig.ALGORITHMS)}\")\n",
        "print(f\"Estimated time: ~{len(ScalabilityConfig.AGENT_POPULATIONS) * len(ScalabilityConfig.TRAINING_MODES) * len(ScalabilityConfig.ALGORITHMS) * 2} minutes (rough estimate)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "results = []\n",
        "total_tests = len(ScalabilityConfig.AGENT_POPULATIONS) * len(ScalabilityConfig.TRAINING_MODES) * len(ScalabilityConfig.ALGORITHMS)\n",
        "current_test = 0\n",
        "\n",
        "for num_agents in ScalabilityConfig.AGENT_POPULATIONS:\n",
        "    for training_mode in ScalabilityConfig.TRAINING_MODES:\n",
        "        for algorithm in ScalabilityConfig.ALGORITHMS:\n",
        "            current_test += 1\n",
        "            print(f\"\\n[{current_test}/{total_tests}] Testing {num_agents} agents, {training_mode.name}, {algorithm.name}\")\n",
        "            \n",
        "            result = run_scalability_test(num_agents, training_mode, algorithm, verbose=False)\n",
        "            results.append(result)\n",
        "            \n",
        "            # Save intermediate results\n",
        "            if current_test % 5 == 0:\n",
        "                df_temp = pd.DataFrame(results)\n",
        "                df_temp.to_csv(ScalabilityConfig.RESULTS_DIR / \"scalability_results_intermediate.csv\", index=False)\n",
        "                print(f\"  üíæ Intermediate results saved\")\n",
        "\n",
        "# Convert results to DataFrame\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "# Save final results\n",
        "df_results.to_csv(ScalabilityConfig.RESULTS_DIR / \"scalability_results_final.csv\", index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"‚úÖ Scalability Analysis Complete!\")\n",
        "print(f\"Total tests: {len(results)}\")\n",
        "print(f\"Successful: {sum(1 for r in results if r['status'] == 'success')}\")\n",
        "print(f\"Failed: {sum(1 for r in results if r['status'] == 'failed')}\")\n",
        "print(f\"Results saved to: {ScalabilityConfig.RESULTS_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚è±Ô∏è Computational Time Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load results if not already in memory\n",
        "if 'df_results' not in locals() or df_results.empty:\n",
        "    try:\n",
        "        df_results = pd.read_csv(ScalabilityConfig.RESULTS_DIR / \"scalability_results_final.csv\")\n",
        "        print(\"‚úÖ Loaded results from file\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"‚ùå No results file found. Please run the scalability tests first.\")\n",
        "        df_results = pd.DataFrame()\n",
        "\n",
        "if not df_results.empty:\n",
        "    # Filter successful tests only\n",
        "    df_success = df_results[df_results['status'] == 'success'].copy()\n",
        "    \n",
        "    print(f\"\\nüìä Results Summary:\")\n",
        "    print(f\"  Total tests: {len(df_results)}\")\n",
        "    print(f\"  Successful: {len(df_success)}\")\n",
        "    print(f\"  Failed: {len(df_results) - len(df_success)}\")\n",
        "    \n",
        "    if len(df_success) > 0:\n",
        "        print(f\"\\n‚è±Ô∏è Computational Time Statistics:\")\n",
        "        print(df_success.groupby(['training_mode', 'algorithm'])['training_time'].describe())\n",
        "        \n",
        "        print(f\"\\nüìà Time per Agent Statistics:\")\n",
        "        print(df_success.groupby(['training_mode', 'algorithm'])['time_per_agent'].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create computational time visualizations\n",
        "if not df_results.empty and len(df_success) > 0:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle('Scalability Analysis: Computational Time', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # Plot 1: Training time vs number of agents (by training mode)\n",
        "    ax1 = axes[0, 0]\n",
        "    for mode in ScalabilityConfig.TRAINING_MODES:\n",
        "        mode_data = df_success[df_success['training_mode'] == mode.name]\n",
        "        if not mode_data.empty:\n",
        "            grouped = mode_data.groupby('num_agents')['training_time'].mean()\n",
        "            ax1.plot(grouped.index, grouped.values, marker='o', label=mode.name, linewidth=2)\n",
        "    ax1.set_xlabel('Number of Agents')\n",
        "    ax1.set_ylabel('Training Time (seconds)')\n",
        "    ax1.set_title('Training Time vs Agent Population (by Training Mode)')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.set_xscale('log')\n",
        "    ax1.set_yscale('log')\n",
        "    \n",
        "    # Plot 2: Training time vs number of agents (by algorithm)\n",
        "    ax2 = axes[0, 1]\n",
        "    for algo in ScalabilityConfig.ALGORITHMS:\n",
        "        algo_data = df_success[df_success['algorithm'] == algo.name]\n",
        "        if not algo_data.empty:\n",
        "            grouped = algo_data.groupby('num_agents')['training_time'].mean()\n",
        "            ax2.plot(grouped.index, grouped.values, marker='s', label=algo.name, linewidth=2)\n",
        "    ax2.set_xlabel('Number of Agents')\n",
        "    ax2.set_ylabel('Training Time (seconds)')\n",
        "    ax2.set_title('Training Time vs Agent Population (by Algorithm)')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.set_xscale('log')\n",
        "    ax2.set_yscale('log')\n",
        "    \n",
        "    # Plot 3: Time per agent vs number of agents\n",
        "    ax3 = axes[1, 0]\n",
        "    for mode in ScalabilityConfig.TRAINING_MODES:\n",
        "        mode_data = df_success[df_success['training_mode'] == mode.name]\n",
        "        if not mode_data.empty:\n",
        "            grouped = mode_data.groupby('num_agents')['time_per_agent'].mean()\n",
        "            ax3.plot(grouped.index, grouped.values, marker='o', label=mode.name, linewidth=2)\n",
        "    ax3.set_xlabel('Number of Agents')\n",
        "    ax3.set_ylabel('Time per Agent (seconds)')\n",
        "    ax3.set_title('Time per Agent vs Agent Population')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 4: Heatmap of training time (agents √ó training_mode √ó algorithm)\n",
        "    ax4 = axes[1, 1]\n",
        "    # Create pivot table for heatmap\n",
        "    pivot_data = df_success.pivot_table(\n",
        "        values='training_time',\n",
        "        index='num_agents',\n",
        "        columns=['training_mode', 'algorithm'],\n",
        "        aggfunc='mean'\n",
        "    )\n",
        "    if not pivot_data.empty:\n",
        "        sns.heatmap(pivot_data, annot=True, fmt='.1f', cmap='YlOrRd', ax=ax4, cbar_kws={'label': 'Time (s)'})\n",
        "        ax4.set_title('Training Time Heatmap')\n",
        "        ax4.set_xlabel('Training Mode √ó Algorithm')\n",
        "        ax4.set_ylabel('Number of Agents')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(ScalabilityConfig.RESULTS_DIR / 'computational_time_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"‚úÖ Computational time visualizations created and saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze scalability trends\n",
        "if not df_results.empty and len(df_success) > 0:\n",
        "    print(\"\\nüìä Scalability Trends Analysis:\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Calculate scaling factors\n",
        "    for mode in ScalabilityConfig.TRAINING_MODES:\n",
        "        for algo in ScalabilityConfig.ALGORITHMS:\n",
        "            combo_data = df_success[\n",
        "                (df_success['training_mode'] == mode.name) & \n",
        "                (df_success['algorithm'] == algo.name)\n",
        "            ]\n",
        "            \n",
        "            if len(combo_data) >= 2:\n",
        "                # Calculate scaling factor (time increase per agent increase)\n",
        "                sorted_data = combo_data.sort_values('num_agents')\n",
        "                \n",
        "                if len(sorted_data) > 1:\n",
        "                    first_time = sorted_data.iloc[0]['training_time']\n",
        "                    first_agents = sorted_data.iloc[0]['num_agents']\n",
        "                    last_time = sorted_data.iloc[-1]['training_time']\n",
        "                    last_agents = sorted_data.iloc[-1]['num_agents']\n",
        "                    \n",
        "                    if first_agents > 0 and first_time > 0:\n",
        "                        scaling_factor = (last_time / first_time) / (last_agents / first_agents)\n",
        "                        \n",
        "                        print(f\"\\n{mode.name} + {algo.name}:\")\n",
        "                        print(f\"  Agents: {first_agents} ‚Üí {last_agents} ({last_agents/first_agents:.1f}x)\")\n",
        "                        print(f\"  Time: {first_time:.2f}s ‚Üí {last_time:.2f}s ({last_time/first_time:.1f}x)\")\n",
        "                        print(f\"  Scaling Factor: {scaling_factor:.2f} (1.0 = linear, <1.0 = sub-linear, >1.0 = super-linear)\")\n",
        "                        \n",
        "                        if scaling_factor < 0.8:\n",
        "                            print(f\"  ‚Üí Sub-linear scaling (efficient)\")\n",
        "                        elif scaling_factor > 1.2:\n",
        "                            print(f\"  ‚Üí Super-linear scaling (inefficient, potential bottleneck)\")\n",
        "                        else:\n",
        "                            print(f\"  ‚Üí Near-linear scaling (expected)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä KPI Impact Analysis\n",
        "\n",
        "*Note: Full KPI analysis requires evaluation episodes and metric collection. This section can be extended to measure social welfare, market efficiency, convergence time, and coordination effectiveness vs agent count.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Results Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not df_results.empty and len(df_success) > 0:\n",
        "    print(\"üìù Scalability Analysis Results Summary\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Best and worst performing combinations\n",
        "    print(\"\\nüèÜ Best Performing Combinations (Fastest Training):\")\n",
        "    best_combos = df_success.nsmallest(5, 'training_time')[['num_agents', 'training_mode', 'algorithm', 'training_time']]\n",
        "    for idx, row in best_combos.iterrows():\n",
        "        print(f\"  {row['num_agents']} agents, {row['training_mode']}, {row['algorithm']}: {row['training_time']:.2f}s\")\n",
        "    \n",
        "    print(\"\\nüêå Worst Performing Combinations (Slowest Training):\")\n",
        "    worst_combos = df_success.nlargest(5, 'training_time')[['num_agents', 'training_mode', 'algorithm', 'training_time']]\n",
        "    for idx, row in worst_combos.iterrows():\n",
        "        print(f\"  {row['num_agents']} agents, {row['training_mode']}, {row['algorithm']}: {row['training_time']:.2f}s\")\n",
        "    \n",
        "    # Recommendations\n",
        "    print(\"\\nüí° Key Findings:\")\n",
        "    \n",
        "    # Best training mode for scalability\n",
        "    mode_avg = df_success.groupby('training_mode')['training_time'].mean().sort_values()\n",
        "    print(f\"\\n  Best Training Mode (avg time): {mode_avg.index[0]} ({mode_avg.iloc[0]:.2f}s)\")\n",
        "    \n",
        "    # Best algorithm for scalability\n",
        "    algo_avg = df_success.groupby('algorithm')['training_time'].mean().sort_values()\n",
        "    print(f\"  Best Algorithm (avg time): {algo_avg.index[0]} ({algo_avg.iloc[0]:.2f}s)\")\n",
        "    \n",
        "    # Scalability limits\n",
        "    max_agents_tested = df_success['num_agents'].max()\n",
        "    max_time = df_success['training_time'].max()\n",
        "    print(f\"\\n  Maximum Agents Tested: {max_agents_tested}\")\n",
        "    print(f\"  Maximum Training Time: {max_time:.2f}s ({max_time/60:.1f} minutes)\")\n",
        "    \n",
        "    print(\"\\nüìÅ Results saved to:\")\n",
        "    print(f\"  - {ScalabilityConfig.RESULTS_DIR / 'scalability_results_final.csv'}\")\n",
        "    print(f\"  - {ScalabilityConfig.RESULTS_DIR / 'computational_time_analysis.png'}\")\n",
        "    \n",
        "    print(\"\\n‚úÖ Analysis complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
